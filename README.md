## Synopsis

This repo is my implementation of the coding questions of assignment2 of Stanford University class:
[CS224n](https://web.stanford.edu/class/cs224n/): Natural Language Processing with Deep Learning

In this assignment we have implemented the followings using python + tensorflow:
- A neural transition-based dependency parser.
- It's important to note that we have implemented Prof Manning & als paper's  [A Fast and Accurate Dependency Parser using Neural Networks1]( http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf)
- And that Google's [Syntaxnet](https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html) is a slight modification of this paper.

The section 3 of this assignment have many mathematical questions involving:
- Deriving the gradients of on RNN language model.
- You can find my (handwritten, correct and more detailed) solutions here:  [CS224n_written_sections_solutions](https://github.com/junteudjio/stanford_NLP_CS224n_written_sections_solutions)


## Contributors

- junior Teudjio Mbativou : https://www.linkedin.com/in/junior-teudjio-3a125b8a


## Acknowledgment

- A big thank you to Stanford university for putting this beautiful learning material open.
- A big thank you to Professors Richard Socher and Chris Manning for teaching the subject in such an intuitive and yet very deep and practical manner.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details
